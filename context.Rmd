--- 
title: "Poverty and Inequality with Complex Survey Data"
author: "Guilherme Jacob, Anthony Damico, and Djalma Pessoa"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output:
  bookdown::tufte_html_book:
    toc: yes
    css: toc.css
  bookdown::pdf_book:
    includes:
      in_header: preamble.tex
    latex_engine: xelatex
    citation_package: natbib
    keep_tex: yes
  bookdown::epub_book: default
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: guilhermejacob/context
description: "A book about the R convey package"
delete_merged_file: yes
---

```{r results='hide', echo=FALSE}
set.seed(2017)
```

# Introduction

The R `convey` library estimates measures of poverty, inequality, and wellbeing.  There are two other R libraries covering this subject, [vardpoor](https://CRAN.R-project.org/package=vardpoor) [@R-vardpoor] and [laeken](https://CRAN.R-project.org/package=laeken) [@R-laeken], however, only `convey` integrates seamlessly with the [R survey package](https://CRAN.R-project.org/package=survey) [@R-survey-article;@R-survey-book;@R-survey].

`convey` is free and open-source software that runs inside the [R environment for statistical computing](https://www.r-project.org/).  Anyone can review and propose changes to [the source code](https://github.com/DjalmaPessoa/convey) for this software.  Readers are welcome to [propose changes to this book](https://github.com/guilhermejacob/context/) as well.

## Installation {#install}

In order to work with the `convey` library, you will need to have R running on your machine.  If you have never used R before, you will need to [install that software](https://www.r-project.org/) before `convey` can be accessed.  Check out [FlowingData](http://flowingdata.com/2012/06/04/resources-for-getting-started-with-r/) for a concise list of resources for new R users.  Once you have R loaded on your machine, you can install..

* the latest released version from [CRAN](https://CRAN.R-project.org/package=convey) with

```R
install.packages("convey")
````

* the latest development version from github with

```R
devtools::install_github("djalmapessoa/convey")
```

In order to know how to cite this package, run `citation("convey")`.

## Complex surveys and statistical inference {#survey}

In this book, we demonstrate how to measure poverty and income concentration in a population based on microdata collected from a complex survey sample.  Most surveys administered by government agencies or larger research organizations utilize a sampling design that violates the assumption of simple random sampling (SRS), including:

1. Different units selection probabilities;
2. Clustering of units;
3. Stratification of clusters;
4. Reweighting to compensate for missing values and other adjustments.

Therefore, basic unweighted R commands such as `mean()` or `glm()` will not properly account for the weighting nor the measures of uncertainty (such as the confidence intervals) present in the dataset.  For some examples of publicly-available complex survey data sets, see [http://asdfree.com]().  

Unlike other software, the R `convey` package does not require that the user specify these parameters throughout the analysis.  So long as the [svydesign object](http://r-survey.r-forge.r-project.org/survey/html/svydesign.html) or [svrepdesign object](http://r-survey.r-forge.r-project.org/survey/html/svrepdesign.html) has been constructed properly at the outset of the analysis, the `convey` package will incorporate the survey design automatically and produce statistics and variances that take the complex sample into account.


## Usage Examples


In the following example, we've loaded the data set `eusilc` from the R library [laeken](https://CRAN.R-project.org/package=laeken) [@R-laeken].

```{r results='hide', message=FALSE, warning=FALSE}
library(laeken)
data(eusilc)
```
Next, we create an object of class `survey.design` using the function `svydesign` of the library survey:

```{r results='hide', message=FALSE, warning=FALSE}
library(survey)
des_eusilc <- svydesign(ids = ~rb030, strata =~db040,  weights = ~rb050, data = eusilc)
```
Right after the creation of the design object `des_eusilc`, we should use the function `convey_prep` that adds an attribute to the survey design which saves information on the design object based upon the whole sample, needed to work with subset designs.

```{r}
library(convey)
des_eusilc <- convey_prep( des_eusilc )
```
To estimate the at-risk-of-poverty rate, we use the function `svyarpt`:

```{r comment=NA}
svyarpr(~eqIncome, design=des_eusilc)
```
To estimate the at-risk-of-poverty rate across domains defined by the variable `db040` we use:

```{r comment=NA}
svyby(~eqIncome, by = ~db040, design = des_eusilc, FUN = svyarpr, deff = FALSE)
```

Using the same data set, we estimate the quintile share ratio: 

```{r comment=NA}
# for the whole population
svyqsr(~eqIncome, design=des_eusilc, alpha1= .20)

# for domains
svyby(~eqIncome, by = ~db040, design = des_eusilc,
      FUN = svyqsr, alpha1= .20, deff = FALSE)

```

These functions can be used as S3 methods for the classes `survey.design` and `svyrep.design`.

Let's create a design object of class `svyrep.design` and run the function `convey_prep` on it:

```{r}
des_eusilc_rep <- as.svrepdesign(des_eusilc, type = "bootstrap")
des_eusilc_rep <- convey_prep(des_eusilc_rep) 
```

and then use the function `svyarpr`:

```{r comment=NA}
svyarpr(~eqIncome, design=des_eusilc_rep)

svyby(~eqIncome, by = ~db040, design = des_eusilc_rep, FUN = svyarpr, deff = FALSE)
```
The functions of the library convey are called in a similar way  to the functions in library survey.

It is also possible to deal with missing values by using the argument `na.rm`.

```{r comment=NA}
# survey.design using a variable with missings
svygini( ~ py010n , design = des_eusilc )
svygini( ~ py010n , design = des_eusilc , na.rm = TRUE )

# svyrep.design using a variable with missings
svygini( ~ py010n , design = des_eusilc_rep )
svygini( ~ py010n , design = des_eusilc_rep , na.rm = TRUE )
```



## Underlying Calculations

In what follows, we often use the linearization method as a tool to produce an approximation for the variance of an estimator. From the linearized variable $z$ of an estimator $T$, we get from the expression \@ref(eq:var) an estimate of the variance of $T$

If $T$ can be expressed as a function of the population totals $T = g(Y_1, Y_2, \ldots, Y_n)$, and if $g$ is linear,  the estimation of the variance of $T = g(Y_1, Y_2, \ldots, Y_n)$ is straightforward. If $g$ is not linear but is a 'smooth' function, then it is possible to approximate the variance of $g(Y_1, Y_2, \ldots, Y_n)$ by the variance of its first order Taylor expansion. For example, we can use Taylor expansion to linearize the ratio of two totals. However, there are situations where Taylor linearization cannot be immediately possible, either because $T$ cannot be expressed as functions of the population totals, or because $g$ is not  a `smooth` function. An example is the case where $T$ is a quantile.

In these cases, it might work an alternative form of linearization of $T$,  by `Influence Function`, as defined in \@ref(eq:lin), proposed in @deville1999. Also, it coud be used replication methods such as `bootstrap` and `jackknife`.

In the `convey` library, there are some basic functions that produce the linearized variables needed to measure income concentration and poverty.  For example, looking at the income variable in some complex survey dataset, the `quantile` of that income variable can be linearized by the function `convey::svyiqalpha` and the sum total below any quantile of the variable is linearized by the function `convey::svyisq`.

From the linearized variables of these basic estimates, it is possible by using rules of composition, valid for influence functions, to derive the influence function of more complex estimates. By definition the influence function is a Gateaux derivative and the rules rules of composition valid for Gateaux derivatives also hold for Influence Functions.

The following property of Gateaux derivatives was often used in the library convey. Let $g$ be a differentiable function of $m$ variables. Suppose we want to compute the influence function of the estimator $g(T_1, T_2,\ldots, T_m)$, knowing the Influence function of the estimators $T_i, i=1,\ldots, m$. Then the following holds:

$$
I(g(T_1, T_2,\ldots, T_m)) = \sum_{i=1}^m \frac{\partial g}{\partial T_i}I(T_i)
$$

In the library convey this rule is implemented by the function `contrastinf` which uses the R function `deriv` to compute the formal partial derivatives $\frac{\partial g}{\partial T_i}$. 

For example, suppose we want to linearize the `Relative median poverty gap`(rmpg), defined as the difference between the at-risk-of-poverty threshold (`arpt`) and the median of incomes less than the `arpt` relative to the `arprt`: 

$$
rmpg= \frac{arpt-medpoor} {arpt}
$$

where `medpoor` is the median of incomes less than `arpt`.

Suppose we know how to linearize `arpt` and `medpoor`, then by applying the function `contrastinf` with 
$$
g(T_1,T_2)= \frac{(T_1 - T_2)}{T_1}
$$
we linearize the `rmpg`.



## The Variance Estimator


Using the notation in @osier2009, the variance of the estimator $T(\hat{M})$ can approximated by:

\begin{equation}
Var\left[T(\hat{M})\right]\cong var\left[\sum_s w_i z_i\right]
(\#eq:var)
\end{equation}

The  `linearized` variable $z$  is given by the derivative of the functional:

\begin{equation}
z_k=lim_{t\rightarrow0}\frac{T(M+t\delta_k)-T(M)}{t}=IT_k(M)
(\#eq:lin)
\end{equation}

where, $\delta_k$ is the Dirac measure in $k$: $\delta_k(i)=1$ if and only if $i=k$.

This **derivative** is called  **Influence Function** and was introduced in the area of **Robust Statistics**. 



## Influence Functions

Some measures of poverty and income concentration are defined by non-differentiable functions so that it is not possible to use Taylor linearization to estimate their variances. An alternative is to use **Influence functions** as described in @deville1999 and @osier2009. The convey library implements this methodology to work with `survey.design` objects and also with `svyrep.design` objects.

Some examples of these measures are:

- At-risk-of-poverty threshold:
$arpt=.60q_{.50}$ where $q_{.50}$ is the income median;

- At-risk-of-poverty rate
$arpr=\frac{\sum_U 1(y_i \leq arpt)}{N}.100$

- Quintile share ratio

$qsr=\frac{\sum_U 1(y_i>q_{.80})}{\sum_U 1(y_i\leq q_{.20})}$

- Gini coefficient
$1+G=\frac{2\sum_U (r_i-1)y_i}{N\sum_Uy_i}$
where $r_i$ is the rank of $y_i$.

Note that it is not possible to use Taylor linearization for these measures because they depend on quantiles and the Gini is defined as a function of ranks. This could be done using the approach proposed by Deville (1999) based upon influence functions. 



Let $U$ be a population of size $N$ and $M$ be a measure that allocates mass one to the set composed by one unit, that is $M(i)=M_i= 1$ if $i\in U$ and $M(i)=0$ if $i\notin U$ 

Now, a population parameter $\theta$ can be expressed as a functional of $M$
$\theta=T(M)$

Examples of such parameters are:

- Total: 
$Y=\sum_Uy_i=\sum_U y_iM_i=\int ydM=T(M)$

- Ratio of two totals:
$R=\frac{Y}{X}=\frac{\int y dM}{\int x dM}=T(M)$

- Cumulative distribution function:
$F(x)=\frac{\sum_U 1(y_i\leq x)}{N}=\frac{\int 1(y\leq x)dM}{\int{dM}}=T(M)$


To estimate these parameters from the sample, we replace the measure $M$ by the estimated measure $\hat{M}$ defined by: $\hat{M}(i)=\hat{M}_i= w_i$ if $i\in s$ and $\hat{M}(i)=0$ if $i\notin s$. 

The estimators of the population parameters can then be expressed as functional of the measure  $\hat{M}$. 

-  Total:
$\hat{Y}=T(\hat{M})=\int yd\hat{M}=\sum_s w_iy_i$

- Ratio of totals:
$\hat{R}=T(\hat{M})=\frac{\int y d\hat{M}}{\int x d\hat{M}}=\frac{\sum_s w_iy_i}{\sum_s w_ix_i}$

- Cumulative distribution function:
$\hat{F}(x)=T(\hat{M})=\frac{\int 1(y\leq x)d\hat{M}}{\int{d\hat{M}}}=\frac{\sum_s w_i 1(y_i\leq x)}{\sum_s w_i}$



## Influence Function Examples


- Total:
$$
\begin{aligned}
IT_k(M)&=lim_{t\rightarrow 0}\frac{T(M+t\delta_k)-T(M)}{t}\\
&=lim_{t\rightarrow 0}\frac{\int y.d(M+t\delta_k)-\int y.dM}{t}\\
&=lim_{t\rightarrow 0}\frac{\int yd(t\delta_k)}{t}=y_k	
\end{aligned}
$$


- Ratio of two totals:
$$
\begin{aligned}
IR_k(M)&=I\left(\frac{U}{V}\right)_k(M)=\frac{V(M)\times IU_k(M)-U(M)\times IV_k(M)}{V(M)^2}\\
&=\frac{X y_k-Y x_k}{X^2}=\frac{1}{X}(y_k-Rx_k)
\end{aligned}
$$

## Examples of Linearization Using the Influence Function

- At-risk-of-poverty threshold:
$$
arpt = 0.6\times m
$$
where $m$ is the median income.

$$
z_k= -\frac{0.6}{f(m)}\times\frac{1}{N}\times\left[I(y_k\leq m-0.5) \right]
$$


- At-risk-of-poverty rate:

\[
arpr=\frac{\sum_U I(y_i \leq t)}{\sum_U w_i}.100
\]
\[
z_k=\frac{1}{N}\left[I(y_k\leq t)-t\right]-\frac{0.6}{N}\times\frac{f(t)}{f(m)}\left[I(y_k\leq m)-0.5\right]
\]

where:

$N$ - population size; 

$t$ - at-risk-of-poverty threshold;

$y_k$ - income of person $k$;

$m$ - median income;

$f$ - income density function;


## Replication Designs

All major functions in the library convey have S3 methods  for the classes: `survey.design`, `svyrep.design` and `DBIdesign`. When the argument `design` is  
a survey design with replicate weights created by the library survey, convey uses the method `svrepdesign`. 

Considering the remarks in [@W85],  p. 163, concerning the deficiency of the `Jackknife` method in estimating the variance of `quantiles`, we adopted the type bootstrap instead. 

The function `bootVar` from the library  `laeken` , [@R-laeken], also uses the bootstrap
method to estimate variances. 

## Decomposition

Some inequality and multidimensional poverty measures can be decomposed. As of December 2016, the decomposition methods in `convey` are limited to group decomposition.

For instance, the generalized entropy index can be decomposed into between and within group components. This sheds light on a very simple question: of the overall inequality, how much can be explained by inequalities between groups and within groups? Since this measure is additive decomposable, one can get estimates of the coefficients, SEs and covariance between components. For a more practical approach, see [@lima2013].

The Alkire-Foster class of multidimensional poverty indices can be decomposed by dimension and groups. This shows how much each group (or dimension) contribute to the overall poverty.

This technique can help understand where and who is more affected by inequality and poverty, contributing to more specific policy and economic analysis.

<!--chapter:end:index.Rmd-->

---
output:
  pdf_document: default
  html_document: default
---
# Poverty Indices {#poverty}

Poverty is an issue discussed since long time ago. As @ravallion2016 points out, Aristotle and Confucius discussed ideas about poverty. In fact, Aristotle's ideas influenced Thomas Aquinas, one of the pillars of Western philosophy. Since then, societies changed, modifying the theories of justice underlying the idea of poverty.

As the concept and the ethics towards poverty change, so does its measurement. From basic measures like the headcount rate to more complex metrics, such as the FGT index, poverty measurement evolved. Nowadays, poverty measures estimates are calculated using household surveys and censuses [@deaton1997]. Yet, only recently the aspects of statistical inference combining such measures and survey designs were explored^[For instance, see @deville1999, @berger2003, @bhat2007, and @osier2009.]. These advances become even more important given the recent efforts in poverty mapping, an analytical method that combined poverty analysis and small area estimation, like @elbers2003 and @bedi2007.

The following subsections shows how poverty estimates and their sampling errors can be estimated using simple commands from the `convey` package.

## At Risk of Poverty Threshold (svyarpt)

The at-risk-of-poverty threshold (ARPT) is a measure used to define the people whose incomes imply a low standard of living in comparison to the general living standards. I.e., even though some people are not below the effective poverty line, those below the ARPT can be considered "almost deprived".

This measure is defined as $0.6$ times the median income for the entire population:

$$
arpt = 0.6 \times median(y),
$$
where, $y$ is the income variable and `median` is estimated for the whole population. The details of the linearization of the `arpt` are discussed by @deville1999 and @osier2009.

---

**A replication example**

The R `vardpoor` package [@vardpoor], created by researchers at the Central Statistical Bureau of Latvia, includes a arpt coefficient calculation using the ultimate cluster method.  The example below reproduces those statistics.

Load and prepare the same data set:

```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the vardpoor library
library(vardpoor)

# load the laeken library
library(laeken)

# load the synthetic EU statistics on income & living conditions
data(eusilc)

# make all column names lowercase
names( eusilc ) <- tolower( names( eusilc ) )

# add a column with the row number
dati <- data.table::data.table(IDd = 1 : nrow(eusilc), eusilc)

# calculate the arpt coefficient
# using the R vardpoor library
varpoord_arpt_calculation <-
	varpoord(
	
		# analysis variable
		Y = "eqincome", 
		
		# weights variable
		w_final = "rb050",
		
		# row number variable
		ID_level1 = "IDd",
		
		# row number variable
		ID_level2 = "IDd",
		
		# strata variable
		H = "db040", 
		
		N_h = NULL ,
		
		# clustering variable
		PSU = "rb030", 
		
		# data.table
		dataset = dati, 
		
		# arpt coefficient function
		type = "linarpt",
	  
	  # poverty threshold range
	  order_quant = 50L ,
	  
		# get linearized variable
	  outp_lin = TRUE
	)


# construct a survey.design
# using our recommended setup
des_eusilc <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc
	)

# immediately run the convey_prep function on it
des_eusilc <- convey_prep( des_eusilc )

# coefficients do match
varpoord_arpt_calculation$all_result$value
coef( svyarpt( ~ eqincome , des_eusilc ) )

# linearized variables do match
# vardpoor
lin_arpt_varpoord<- varpoord_arpt_calculation$lin_out$lin_arpt
# convey 
lin_arpt_convey <- attr(svyarpt( ~ eqincome , des_eusilc ),"lin")

# check equality
all.equal(lin_arpt_varpoord, lin_arpt_convey )

# variances do not match exactly
attr( svyarpt( ~ eqincome , des_eusilc ) , 'var' )
varpoord_arpt_calculation$all_result$var

# standard errors do not match exactly
varpoord_arpt_calculation$all_result$se
SE( svyarpt( ~ eqincome , des_eusilc ) )
```

The variance estimate is computed by using the approximation defined in \@ref(eq:var), where the linearized variable $z$ is defined by \@ref(eq:lin). The functions `convey::svyarpt` and `vardpoor::linarpt` produce the same linearized variable $z$.

However, the measures of uncertainty do not line up, because `library(vardpoor)` defaults to an ultimate cluster method that can be replicated with an alternative setup of the `survey.design` object.

```{r}
# within each strata, sum up the weights
cluster_sums <- aggregate( eusilc$rb050 , list( eusilc$db040 ) , sum )

# name the within-strata sums of weights the `cluster_sum`
names( cluster_sums ) <- c( "db040" , "cluster_sum" )

# merge this column back onto the data.frame
eusilc <- merge( eusilc , cluster_sums )

# construct a survey.design
# with the fpc using the cluster sum
des_eusilc_ultimate_cluster <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc , 
		fpc = ~ cluster_sum 
	)

# again, immediately run the convey_prep function on the `survey.design`
des_eusilc_ultimate_cluster <- convey_prep( des_eusilc_ultimate_cluster )

# matches
attr( svyarpt( ~ eqincome , des_eusilc_ultimate_cluster ) , 'var' )
varpoord_arpt_calculation$all_result$var

# matches
varpoord_arpt_calculation$all_result$se
SE( svyarpt( ~ eqincome , des_eusilc_ultimate_cluster ) )
```

For additional usage examples of `svyarpt`, type `?convey::svyarpt` in the R console.

## At Risk of Poverty Ratio (svyarpr)

The at-risk-of-poverty rate (ARPR) is the share of persons with an income below the at-risk-of-poverty threshold (`arpt`). The logic behind this measure is that although most people below the ARPT cannot be considered "poor", they are the ones most vulnerable to becoming poor in the event of a negative economic phenomenon.

The ARPR is a composite estimate, taking into account both the sampling error in the proportion itself and that in the ARPT estimate. The details of the linearization of the `arpr` and are discussed by @deville1999 and @osier2009.

---

**A replication example**

The R `vardpoor` package [@vardpoor], created by researchers at the Central Statistical Bureau of Latvia, includes a ARPR coefficient calculation using the ultimate cluster method.  The example below reproduces those statistics.

Load and prepare the same data set:

```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the vardpoor library
library(vardpoor)

# load the vardpoor library
library(laeken)

# load the synthetic EU statistics on income & living conditions
data(eusilc)

# make all column names lowercase
names( eusilc ) <- tolower( names( eusilc ) )

# add a column with the row number
dati <- data.table::data.table(IDd = 1 : nrow(eusilc), eusilc)

# calculate the arpr coefficient
# using the R vardpoor library
varpoord_arpr_calculation <-
	varpoord(
	
		# analysis variable
		Y = "eqincome", 
		
		# weights variable
		w_final = "rb050",
		
		# row number variable
		ID_level1 = "IDd",
		
		# row number variable
		ID_level2 = "IDd",
		
		# strata variable
		H = "db040", 
		
		N_h = NULL ,
		
		# clustering variable
		PSU = "rb030", 
		
		# data.table
		dataset = dati, 
		
		# arpr coefficient function
		type = "linarpr",
	  
	  # poverty threshold range
	  order_quant = 50L ,
	  	  
	  # get linearized variable
	  outp_lin = TRUE
		
	)


# construct a survey.design
# using our recommended setup
des_eusilc <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc
	)

# immediately run the convey_prep function on it
des_eusilc <- convey_prep( des_eusilc )

# coefficients do match
varpoord_arpr_calculation$all_result$value
coef( svyarpr( ~ eqincome , des_eusilc ) ) * 100

# linearized variables do match
# vardpoor
lin_arpr_varpoord<- varpoord_arpr_calculation$lin_out$lin_arpr
# convey 
lin_arpr_convey <- attr(svyarpr( ~ eqincome , des_eusilc ),"lin")

# check equality
all.equal(lin_arpr_varpoord,100*lin_arpr_convey )



# variances do not match exactly
attr( svyarpr( ~ eqincome , des_eusilc ) , 'var' ) * 10000
varpoord_arpr_calculation$all_result$var

# standard errors do not match exactly
varpoord_arpr_calculation$all_result$se
SE( svyarpr( ~ eqincome , des_eusilc ) ) * 100
```
The variance estimate is computed by using the approximation defined in \@ref(eq:var), where the linearized variable $z$ is defined by \@ref(eq:lin). The functions `convey::svyarpr` and `vardpoor::linarpr` produce the same linearized variable $z$.

However, the measures of uncertainty do not line up, because `library(vardpoor)` defaults to an ultimate cluster method that can be replicated with an alternative setup of the `survey.design` object.

```{r}
# within each strata, sum up the weights
cluster_sums <- aggregate( eusilc$rb050 , list( eusilc$db040 ) , sum )

# name the within-strata sums of weights the `cluster_sum`
names( cluster_sums ) <- c( "db040" , "cluster_sum" )

# merge this column back onto the data.frame
eusilc <- merge( eusilc , cluster_sums )

# construct a survey.design
# with the fpc using the cluster sum
des_eusilc_ultimate_cluster <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc , 
		fpc = ~ cluster_sum 
	)

# again, immediately run the convey_prep function on the `survey.design`
des_eusilc_ultimate_cluster <- convey_prep( des_eusilc_ultimate_cluster )

# matches
attr( svyarpr( ~ eqincome , des_eusilc_ultimate_cluster ) , 'var' ) * 10000
varpoord_arpr_calculation$all_result$var

# matches
varpoord_arpr_calculation$all_result$se
SE( svyarpr( ~ eqincome , des_eusilc_ultimate_cluster ) ) * 100
```

For additional usage examples of `svyarpr`, type `?convey::svyarpr` in the R console.

## Relative Median Income Ratio (svyrmir)

The relative median income ratio (rmir) is the ratio of the median income of people aged above a value (65) to the median of people aged below the same value. In mathematical terms,

$$
rmir = \frac{median\{y_i; age_i >65 \}}{median\{y_i; age_i \leq 65 \}}.
$$

The details of the linearization of the `rmir` and are discussed by @deville1999 and @osier2009. 

---

**A replication example**

The R `vardpoor` package [@vardpoor], created by researchers at the Central Statistical Bureau of Latvia, includes a rmir coefficient calculation using the ultimate cluster method.  The example below reproduces those statistics.

Load and prepare the same data set:

```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the vardpoor library
library(vardpoor)

# load the vardpoor library
library(laeken)

# load the synthetic EU statistics on income & living conditions
data(eusilc)

# make all column names lowercase
names( eusilc ) <- tolower( names( eusilc ) )

# add a column with the row number
dati <- data.table::data.table(IDd = 1 : nrow(eusilc), eusilc)

# calculate the rmir coefficient
# using the R vardpoor library
varpoord_rmir_calculation <-
	varpoord(
	
		# analysis variable
		Y = "eqincome", 
		
		# weights variable
		w_final = "rb050",
		
		# row number variable
		ID_level1 = "IDd",
		
		# row number variable
		ID_level2 = "IDd",
		
		# strata variable
		H = "db040", 
		
		N_h = NULL ,
		
		# clustering variable
		PSU = "rb030", 
		
		# data.table
		dataset = dati,
	  
	  # age variable
	  age = "age",
		
		# rmir coefficient function
		type = "linrmir",
	  
	  # poverty threshold range
	  order_quant = 50L ,
	  
	  # get linearized variable
	  outp_lin = TRUE
		
	)



# construct a survey.design
# using our recommended setup
des_eusilc <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc
	)

# immediately run the convey_prep function on it
des_eusilc <- convey_prep( des_eusilc )

# coefficients do match
varpoord_rmir_calculation$all_result$value
coef( svyrmir( ~ eqincome , des_eusilc, age = ~age ) ) 

# linearized variables do match
# vardpoor
lin_rmir_varpoord<- varpoord_rmir_calculation$lin_out$lin_rmir
# convey 
lin_rmir_convey <- attr(svyrmir( ~ eqincome , des_eusilc, age = ~age ),"lin")

# check equality
all.equal(lin_rmir_varpoord, lin_rmir_convey[,1] )

# variances do not match exactly
attr( svyrmir( ~ eqincome , des_eusilc, age = ~age ) , 'var' ) 
varpoord_rmir_calculation$all_result$var

# standard errors do not match exactly
varpoord_rmir_calculation$all_result$se
SE( svyrmir( ~ eqincome , des_eusilc , age = ~age) ) 
```

The variance estimate is computed by using the approximation defined in \@ref(eq:var), where the linearized variable $z$ is defined by \@ref(eq:lin). The functions `convey::svyrmir` and `vardpoor::linrmir` produce the same linearized variable $z$.

However, the measures of uncertainty do not line up, because `library(vardpoor)` defaults to an ultimate cluster method that can be replicated with an alternative setup of the `survey.design` object.

```{r}
# within each strata, sum up the weights
cluster_sums <- aggregate( eusilc$rb050 , list( eusilc$db040 ) , sum )

# name the within-strata sums of weights the `cluster_sum`
names( cluster_sums ) <- c( "db040" , "cluster_sum" )

# merge this column back onto the data.frame
eusilc <- merge( eusilc , cluster_sums )

# construct a survey.design
# with the fpc using the cluster sum
des_eusilc_ultimate_cluster <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc , 
		fpc = ~ cluster_sum 
	)

# again, immediately run the convey_prep function on the `survey.design`
des_eusilc_ultimate_cluster <- convey_prep( des_eusilc_ultimate_cluster )

# matches
attr( svyrmir( ~ eqincome , des_eusilc_ultimate_cluster , age = ~age ) , 'var' ) 
varpoord_rmir_calculation$all_result$var

# matches
varpoord_rmir_calculation$all_result$se
SE( svyrmir( ~ eqincome , des_eusilc_ultimate_cluster, age = ~age ) ) 
```

For additional usage examples of `svyrmir`, type `?convey::svyrmir` in the R console.

## Relative Median Poverty Gap (svyrmpg)

The relative median poverty gap (`rmpg`) is the relative difference between the median income of people having income below the `arpt` and the `arpt` itself:

$$
rmpg = \frac{median\{y_i, y_i<arpt\}-arpt}{arpt}
$$
The details of the linearization of the `rmpg` are discussed by @deville1999 and @osier2009.

---

**A replication example**

The R `vardpoor` package [@vardpoor], created by researchers at the Central Statistical Bureau of Latvia, includes a rmpg coefficient calculation using the ultimate cluster method.  The example below reproduces those statistics.

Load and prepare the same data set:

```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the vardpoor library
library(vardpoor)

# load the vardpoor library
library(laeken)

# load the synthetic EU statistics on income & living conditions
data(eusilc)

# make all column names lowercase
names( eusilc ) <- tolower( names( eusilc ) )

# add a column with the row number
dati <- data.table::data.table(IDd = 1 : nrow(eusilc), eusilc)

# calculate the rmpg coefficient
# using the R vardpoor library
varpoord_rmpg_calculation <-
	varpoord(
	
		# analysis variable
		Y = "eqincome", 
		
		# weights variable
		w_final = "rb050",
		
		# row number variable
		ID_level1 = "IDd",

		# row number variable
		ID_level2 = "IDd",
				
		# strata variable
		H = "db040", 
		
		N_h = NULL ,
		
		# clustering variable
		PSU = "rb030", 
		
		# data.table
		dataset = dati, 
		
		# rmpg coefficient function
		type = "linrmpg",
	  
	  # poverty threshold range
	  order_quant = 50L ,
	  
	  # get linearized variable
	  outp_lin = TRUE
		
	)



# construct a survey.design
# using our recommended setup
des_eusilc <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc
	)

# immediately run the convey_prep function on it
des_eusilc <- convey_prep( des_eusilc )

# coefficients do match
varpoord_rmpg_calculation$all_result$value
coef( svyrmpg( ~ eqincome , des_eusilc ) ) * 100

# linearized variables do match
# vardpoor
lin_rmpg_varpoord<- varpoord_rmpg_calculation$lin_out$lin_rmpg
# convey 
lin_rmpg_convey <- attr(svyrmpg( ~ eqincome , des_eusilc ),"lin")

# check equality
all.equal(lin_rmpg_varpoord, 100*lin_rmpg_convey[,1] )

# variances do not match exactly
attr( svyrmpg( ~ eqincome , des_eusilc ) , 'var' ) * 10000
varpoord_rmpg_calculation$all_result$var

# standard errors do not match exactly
varpoord_rmpg_calculation$all_result$se
SE( svyrmpg( ~ eqincome , des_eusilc ) ) * 100
```

The variance estimate is computed by using the approximation defined in \@ref(eq:var), where the linearized variable $z$ is defined by \@ref(eq:lin). The functions `convey::svyrmpg` and `vardpoor::linrmpg` produce the same linearized variable $z$.

However, the measures of uncertainty do not line up, because `library(vardpoor)` defaults to an ultimate cluster method that can be replicated with an alternative setup of the `survey.design` object.

```{r}
# within each strata, sum up the weights
cluster_sums <- aggregate( eusilc$rb050 , list( eusilc$db040 ) , sum )

# name the within-strata sums of weights the `cluster_sum`
names( cluster_sums ) <- c( "db040" , "cluster_sum" )

# merge this column back onto the data.frame
eusilc <- merge( eusilc , cluster_sums )

# construct a survey.design
# with the fpc using the cluster sum
des_eusilc_ultimate_cluster <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc , 
		fpc = ~ cluster_sum 
	)

# again, immediately run the convey_prep function on the `survey.design`
des_eusilc_ultimate_cluster <- convey_prep( des_eusilc_ultimate_cluster )

# matches
attr( svyrmpg( ~ eqincome , des_eusilc_ultimate_cluster ) , 'var' ) * 10000
varpoord_rmpg_calculation$all_result$var

# matches
varpoord_rmpg_calculation$all_result$se
SE( svyrmpg( ~ eqincome , des_eusilc_ultimate_cluster ) ) * 100
```

For additional usage examples of `svyrmpg`, type `?convey::svyrmpg` in the R console.

## Median Income Below the At Risk of Poverty Threshold  (svypoormed)

Median income below the at-risk-of-poverty- threshold (poormed) is median of incomes of people having the income below the `arpt`:

$$
poormed = median\{y_i; y_i< arpt\}
$$
The details of the linearization of the `poormed` are discussed by @deville1999 and @osier2009.

---

**A replication example**

The R `vardpoor` package [@vardpoor], created by researchers at the Central Statistical Bureau of Latvia, includes a poormed coefficient calculation using the ultimate cluster method.  The example below reproduces those statistics.

Load and prepare the same data set:

```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the vardpoor library
library(vardpoor)

# load the vardpoor library
library(laeken)

# load the synthetic EU statistics on income & living conditions
data(eusilc)

# make all column names lowercase
names( eusilc ) <- tolower( names( eusilc ) )

# add a column with the row number
dati <- data.table::data.table(IDd = 1 : nrow(eusilc), eusilc)

# calculate the poormed coefficient
# using the R vardpoor library
varpoord_poormed_calculation <-
	varpoord(
	
		# analysis variable
		Y = "eqincome", 
		
		# weights variable
		w_final = "rb050",
		
		# row number variable
		ID_level1 = "IDd",

		# row number variable
		ID_level2 = "IDd",
				
		# strata variable
		H = "db040", 
		
		N_h = NULL ,
		
		# clustering variable
		PSU = "rb030", 
		
		# data.table
		dataset = dati, 
		
		# poormed coefficient function
		type = "linpoormed",
	  
	  # poverty threshold range
	  order_quant = 50L ,
	  
	  # get linearized variable
	  outp_lin = TRUE
		
	)



# construct a survey.design
# using our recommended setup
des_eusilc <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc
	)

# immediately run the convey_prep function on it
des_eusilc <- convey_prep( des_eusilc )

# coefficients do match
varpoord_poormed_calculation$all_result$value
coef( svypoormed( ~ eqincome , des_eusilc ) )

# linearized variables do match
# vardpoor
lin_poormed_varpoord<- varpoord_poormed_calculation$lin_out$lin_poormed
# convey 
lin_poormed_convey <- attr(svypoormed( ~ eqincome , des_eusilc ),"lin")

# check equality
all.equal(lin_poormed_varpoord, lin_poormed_convey )

# variances do not match exactly
attr( svypoormed( ~ eqincome , des_eusilc ) , 'var' )
varpoord_poormed_calculation$all_result$var

# standard errors do not match exactly
varpoord_poormed_calculation$all_result$se
SE( svypoormed( ~ eqincome , des_eusilc ) )
```

The variance estimate is computed by using the approximation defined in \@ref(eq:var), where the linearized variable $z$ is defined by \@ref(eq:lin). The functions `convey::svypoormed` and `vardpoor::linpoormed` produce the same linearized variable $z$.

However, the measures of uncertainty do not line up, because `library(vardpoor)` defaults to an ultimate cluster method that can be replicated with an alternative setup of the `survey.design` object.

```{r}
# within each strata, sum up the weights
cluster_sums <- aggregate( eusilc$rb050 , list( eusilc$db040 ) , sum )

# name the within-strata sums of weights the `cluster_sum`
names( cluster_sums ) <- c( "db040" , "cluster_sum" )

# merge this column back onto the data.frame
eusilc <- merge( eusilc , cluster_sums )

# construct a survey.design
# with the fpc using the cluster sum
des_eusilc_ultimate_cluster <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc , 
		fpc = ~ cluster_sum 
	)

# again, immediately run the convey_prep function on the `survey.design`
des_eusilc_ultimate_cluster <- convey_prep( des_eusilc_ultimate_cluster )

# matches
attr( svypoormed( ~ eqincome , des_eusilc_ultimate_cluster ) , 'var' )
varpoord_poormed_calculation$all_result$var

# matches
varpoord_poormed_calculation$all_result$se
SE( svypoormed( ~ eqincome , des_eusilc_ultimate_cluster ) )
```

For additional usage examples of `svypoormed`, type `?convey::svypoormed` in the R console.

## Foster-Greer-Thorbecke class (svyfgt, svyfgtdec)

@foster1984 proposed a family of indicators to measure poverty.  This class of $FGT$ measures, can be defined as

\[
p=\frac{1}{N}\sum_{k\in U}h(y_{k},\theta ), 
\]

where

\[
h(y_{k},\theta )=\left[ \frac{(\theta -y_{k})}{\theta }\right] ^{\gamma
}\delta \left\{ y_{k}\leq \theta \right\} , 
\]

where: $\theta$ is the poverty threshold; $\delta$ the indicator function that assigns value $1$ if the condition $\{y_{k}\leq \theta \}$ is satisfied and $0$ otherwise, and $\gamma$ is a non-negative constant.

If $\gamma =0$, the FGT(0) equals the poverty headcount ratio, which accounts for the spread of poverty. If $\gamma =1$, FGT(1) is the mean of the normalized income shortfall of the poor. By doing so, the measure takes into account both the spread and the intensity of poverty. When $\gamma =2$, the relative weight of larger shortfalls increases even more, which yields a measure that accounts for poverty severity, i.e., the inequality among the poor. This way, a transfer from a poor person to an even poorer person would reduce the FGT(2).

Although @foster1984 already presented a decomposition for the FGT(2) index, @aristondo2010 provided a general formula that decomposes the FGT($\gamma$) for any $\gamma \geqslant 2$. Put simply, any such FGT($\gamma$) index can be seen as function of the headcount ratio, the average normalized income gap among the poor and a generalized entropy index of the normalized income gaps among poor. In mathematical terms,

\[
FGT_\gamma = FGT_0 \cdot I^\gamma \cdot \big[ 1 + \big( \gamma^2 -\gamma \big) GEI_\gamma^* \big] , \text{ } \gamma \geq 2
\]

where $I$ is the average normalized income gap among the poor and $GEI_\gamma^*$ is a generalized entropy index of such income gaps among the poor.

This result is particularly useful, as one can attribute cross-sectional differences of a FGT index to differences in the spread, depth and inequality of poverty.

The FGT poverty class and its decomposition is implemented in the library convey by the function `svyfgt` and `svyfgtdec`, respectively.
The argument `thresh_type` of this function defines the type of poverty threshold adopted.
There are three possible choices:

1. `abs` -- fixed and given by the argument thresh_value
2. `relq` -- a proportion of a quantile fixed by the argument `proportion` and the quantile is defined by the argument `order`.
3. `relm` -- a proportion of the mean fixed the argument `proportion`

The quantile and the mean involved in the definition of the threshold are estimated for the whole population. When $\gamma=0$ and $\theta= .6*MED$ the measure is equal to the indicator `arpr` computed by the function  `svyarpr`. The linearization of the FGT(0) is presented in @berger2003.

Next, we give some examples of the function `svyfgt` to estimate the values of the FGT poverty index.

Consider first the poverty threshold fixed ($\gamma=0$) in the value $10000$. The headcount ratio (FGT0) is

```{r comment=NA}
svyfgt(~eqincome, des_eusilc, g=0, abs_thresh=10000)
```

The poverty gap ratio (FGT(1)) ($\gamma=1$) index for the poverty threshold fixed at the same value is

```{r comment=NA}
svyfgt(~eqincome, des_eusilc, g=1, abs_thresh=10000)
```

To estimate the FGT(0) with the poverty threshold fixed at $0.6* MED$ we fix the argument `type_thresh="relq"` and use the default values for `percent` and `order`:

```{r comment=NA}
svyfgt(~eqincome, des_eusilc, g=0, type_thresh= "relq")
```
that matches the estimate obtained by

```{r comment=NA}
svyarpr(~eqincome, design=des_eusilc, .5, .6)
```
To estimate the poverty gap ratio with the poverty threshold equal to $0.6*MEAN$, we use:

```{r comment=NA}
svyfgt(~eqincome, des_eusilc, g=1, type_thresh= "relm")
```

---

**A replication example**

In July 2006, @jenkins2006 presented at the North American Stata Users' Group Meetings on the stata Atkinson Index command.  The example below reproduces those statistics.

In order to match the presentation's results using the `svyfgt` function from the convey library, the poverty threshold was considered absolute despite being directly estimated from the survey sample.  This effectively treats the variance of the estimated poverty threshold as zero; `svyfgt` does not account for the uncertainty of the poverty threshold when the level has been stated as absolute with the `abs_thresh=` parameter.  In general, we would instead recommend using either `relq` or `relm` in the `type_thresh=` parameter in order to account for the added uncertainty of the poverty threshold calculation.  This example serves only to show that `svyfgt` behaves properly as compared to other software.

Load and prepare the same data set:
```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the foreign library
library(foreign)

# create a temporary file on the local disk
tf <- tempfile()

# store the location of the presentation file
presentation_zip <- "http://repec.org/nasug2006/nasug2006_jenkins.zip"

# download jenkins' presentation to the temporary file
download.file( presentation_zip , tf , mode = 'wb' )

# unzip the contents of the archive
presentation_files <- unzip( tf , exdir = tempdir() )

# load the institute for fiscal studies' 1981, 1985, and 1991 data.frame objects
x81 <- read.dta( grep( "ifs81" , presentation_files , value = TRUE ) )
x85 <- read.dta( grep( "ifs85" , presentation_files , value = TRUE ) )
x91 <- read.dta( grep( "ifs91" , presentation_files , value = TRUE ) )

# NOTE: we recommend using ?convey::svyarpt rather than this unweighted calculation #

# calculate 60% of the unweighted median income in 1981
unwtd_arpt81 <- quantile( x81$eybhc0 , 0.5 ) * .6

# calculate 60% of the unweighted median income in 1985
unwtd_arpt85 <- quantile( x85$eybhc0 , 0.5 ) * .6

# calculate 60% of the unweighted median income in 1991
unwtd_arpt91 <- quantile( x91$eybhc0 , 0.5 ) * .6

# stack each of these three years of data into a single data.frame
x <- rbind( x81 , x85 , x91 )
```

Replicate the author's survey design statement from stata code..
```
. ge poor = (year==1981)*(x < $z_81) + (year==1985)*(x < $z_85) +  (year==1991)*(x < $z_91)
. * account for clustering within HHs 
. svyset hrn [pweight = wgt]
```

.. into R code:

```{r}
# initiate a linearized survey design object
y <- svydesign( ~ hrn , data = x , weights = ~ wgt )

# immediately run the `convey_prep` function on the survey design
z <- convey_prep( y )
```

Replicate the author's headcount ratio results with stata..
```
. svy: mean poor if year == 1981
(running mean on estimation sample)

Survey: Mean estimation

Number of strata =       1          Number of obs    =    9772
Number of PSUs   =    7476          Population size  = 5.5e+07
                                    Design df        =    7475

--------------------------------------------------------------
             |             Linearized
             |       Mean   Std. Err.     [95% Conf. Interval]
-------------+------------------------------------------------
        poor |   .1410125   .0044859       .132219     .149806
--------------------------------------------------------------

. svy: mean poor if year == 1985
(running mean on estimation sample)

Survey: Mean estimation

Number of strata =       1          Number of obs    =    8991
Number of PSUs   =    6972          Population size  = 5.5e+07
                                    Design df        =    6971

--------------------------------------------------------------
             |             Linearized
             |       Mean   Std. Err.     [95% Conf. Interval]
-------------+------------------------------------------------
        poor |    .137645   .0046531      .1285235    .1467665
--------------------------------------------------------------

. svy: mean poor if year == 1991
(running mean on estimation sample)

Survey: Mean estimation

Number of strata =       1          Number of obs    =    6468
Number of PSUs   =    5254          Population size  = 5.6e+07
                                    Design df        =    5253

--------------------------------------------------------------
             |             Linearized
             |       Mean   Std. Err.     [95% Conf. Interval]
-------------+------------------------------------------------
        poor |   .2021312   .0062077      .1899615    .2143009
--------------------------------------------------------------
```

..using R code:

```{r}
headcount_81 <- 
	svyfgt( 
		~ eybhc0 , 
		subset( z , year == 1981 ) , 
		g = 0 , 
		abs_thresh = unwtd_arpt81
	)

headcount_81

confint( headcount_81 , df = degf( subset( z , year == 1981 ) ) )

headcount_85 <- 
	svyfgt( 
		~ eybhc0 , 
		subset( z , year == 1985 ) , 
		g = 0 , 
		abs_thresh = unwtd_arpt85 
	)
	
headcount_85

confint( headcount_85 , df = degf( subset( z , year == 1985 ) ) )

headcount_91 <- 
	svyfgt( 
		~ eybhc0 , 
		subset( z , year == 1991 ) , 
		g = 0 , 
		abs_thresh = unwtd_arpt91 
	)

headcount_91
	
confint( headcount_91 , df = degf( subset( z , year == 1991 ) ) )
```

Confirm this replication applies for the normalized poverty gap as well, comparing stata code..
```
. ge ngap = poor*($z_81- x)/$z_81 if year == 1981

. svy: mean ngap if year == 1981
(running mean on estimation sample)

Survey: Mean estimation

Number of strata =       1          Number of obs    =    9772
Number of PSUs   =    7476          Population size  = 5.5e+07
                                    Design df        =    7475

--------------------------------------------------------------
             |             Linearized
             |       Mean   Std. Err.     [95% Conf. Interval]
-------------+------------------------------------------------
        ngap |   .0271577   .0013502      .0245109    .0298044
--------------------------------------------------------------
```

..to R code:

```{r}
norm_pov_81 <- 
	svyfgt( 
		~ eybhc0 , 
		subset( z , year == 1981 ) , 
		g = 1 , 
		abs_thresh = unwtd_arpt81
	)
	
norm_pov_81

confint( norm_pov_81 , df = degf( subset( z , year == 1981 ) ) )
```

For additional usage examples of `svyfgt`, type `?convey::svyfgt` in the R console.

## Watts poverty measure (svywatts, svywattsdec)

The measure proposed in @watts1968 satisfies a number of desirable poverty measurement axioms and is known to be one of the first distribution-sensitive poverty measures, as noted by @haughton2009. It is defined as

\[
Watts = \frac{1}{N} \sum_{i \in U} \log{ \bigg( \frac{y_i}{\theta} \bigg) \delta ( y_i \leqslant \theta) }.
\]

@murdoch1998 points out that the Watts poverty index can provide an estimate of the expected time to exit poverty. Given the expected growth rate of income per capita among the poor, $g$, the expected time taken to exit poverty $T_\theta$ would be

\[
T_\theta = \frac{Watts}{g}.
\]

The Watts poverty index also has interesting decomposition properties. @blackburn1989 proposed a decomposition for the Watts poverty index, rewriting it in terms of the headcount ratio, the Watts poverty gap ratio and the mean log deviaton of poor incomes^[The mean log deviation (also known as Theil-L or Bourguignon-Theil index) is an inequality measure of the generalized entropy class. The family of generalized entropy indices is discussed in the next chapter.]. Mathematically,

\[
Watts = FGT_0 \big( I_w + L_* \big)
\]

where $I_w = \log(\theta/\mu_*)$ is the Watts poverty gap ratio^[ $\mu_*$ stands for the average income among the poor.] and $L_*$ is the mean log deviation of incomes among the poor. This can be estimated using the `svywattsdec` function.

This result can also be interpreted as a decomposition of the time taken to exit poverty, since

\[
\begin{aligned}
T_\theta &= \frac{Watts}{g} \\ 
&= \frac{FGT_0}{g} \big( I_w + L_* \big)
\end{aligned}
\]

As @murdoch1998 points out, if the income among the poor is equally distributed (i.e., $L_*=0$), the time taken to exit poverty is simply $FGT_0 I_w / g$. Therefore, $FGT_0 L_* / g$ can be seen as the additional time needed to exit poverty as a result of the inequality among the poor.

## Clark-Hemming-Ulph class of poverty measures (svychu)

@clark1981 proposes two classes of distribution-sensitive poverty measures. Yet, the poverty measurement literature focuses on the second class^[See @atkinson1987 and @verma2011, for instance.], expressed as

\[
CHU_\alpha = \begin{cases}
    \frac{1}{\alpha N} \sum_{i \in U} \big[ 1-(y_i/\theta)^\alpha \big] \cdot \delta ( y_i \leqslant \theta ) , & \alpha \leqslant 1 , \alpha \neq 0 \\
    1 - \bigg( \prod_{i \in U} y_i^{\delta ( y_i \leqslant \theta )} \bigg)^{1/N} \bigg/ \theta , &  \alpha = 0
\end{cases}
\]

As an special case, $CHU_0 = 1 - \exp{(-Watts)}$. The $\alpha$ parameter defines the sensivity towards regressive income transfers among the poor, such that the lower its value, larger is the regressive transfer impact on the index. When $\alpha \rightarrow 1$, $CHU_1 = FGT_0 \cdot I$, a measure insensitive to regressive income transfers among the poor. 

<!--chapter:end:01-poverty.Rmd-->

# Inequality Measurement {#inequality}

Another problem faced by societies is inequality. Economic inequality can have several different meanings: income, education, resources, opportunities, wellbeing, etc. Usually, studies on economic inequality focus on income distribution.

Most inequality data comes from censuses and household surveys. Therefore, in order to produce reliable estimates from this samples, appropriate procedures are necessary.

This chapter presents brief presentations on inequality measures, also providing replication examples if possible. It starts with an initial attempt to measure the inequality between two groups of a population; then, it presents ideas of overall inequality indices, moving from the quintile share ratio to the Lorenz curve and measures derived from it; then, it discusses the concept of entropy and presents inequality measures based on it. Finally, it ends with a discussion regarding which inequality measure should be used.

## The Gender Pay Gap (svygpg)

Although the $GPG$ is not an inequality measure in the usual sense, it can still be an useful instrument to evaluate the discrimination among men and women. Put simply, it expresses the relative difference between the average hourly earnings of men and women, presenting it as a percentage of the average of hourly earnings of men. 

In mathematical terms, this index can be described as,

\[ GPG = \frac{ \bar{y}_{male} - \bar{y}_{female} }{ \bar{y}_{male} } \],

which is precisely the estimator used in the package. As we can see from the formula, if there is no difference among classes, $GPG = 0$. Else, if $GPG > 0$, it means that the average hourly income received by women are $GPG$ percent smaller than men's. For negative $GPG$, it means that women's hourly earnings are $GPG$ percent larger than men's. In other words, the larger the $GPG$, larger is the shortfall of women's hourly earnings. 

We can also develop a more straightforward idea: for every \$1 raise in men's hourly earnings, women's hourly earnings are expected to increase \$$(1-GPG)$. For instance, assuming $GPG = 0.8$, for every \$1.00 increase in men's average hourly earnings, women's hourly earnings would increase only \$0.20.

The details of the linearization of the `GPG` are discussed by @deville1999 and @osier2009.

---

**A replication example**

The R `vardpoor` package [@vardpoor], created by researchers at the Central Statistical Bureau of Latvia, includes a gpg coefficient calculation using the ultimate cluster method. The example below reproduces those statistics.

Load and prepare the same data set:

```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the vardpoor library
library(vardpoor)

# load the laeken library
library(laeken)

# load the synthetic EU statistics on income & living conditions
data(eusilc)

# make all column names lowercase
names( eusilc ) <- tolower( names( eusilc ) )

# coerce the gender variable to numeric 1 or 2
eusilc$one_two <- as.numeric( eusilc$rb090 == "female" ) + 1

# add a column with the row number
dati <- data.table::data.table(IDd = 1 : nrow(eusilc), eusilc)

# calculate the gpg coefficient
# using the R vardpoor library
varpoord_gpg_calculation <-
	varpoord(
	
		# analysis variable
		Y = "eqincome", 
		
		# weights variable
		w_final = "rb050",
		
		# row number variable
		ID_level1 = "IDd",
		
		# row number variable
		ID_level2 = "IDd",
		
		# strata variable
		H = "db040", 
		
		N_h = NULL ,
		
		# clustering variable
		PSU = "rb030", 
		
		# data.table
		dataset = dati, 
		
		# gpg coefficient function
		type = "lingpg" ,
		
		# gender variable
		gender = "one_two",
	  
	  # poverty threshold range
	  order_quant = 50L ,
	  
	  # get linearized variable
	  outp_lin = TRUE
	)



# construct a survey.design
# using our recommended setup
des_eusilc <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc
	)

# immediately run the convey_prep function on it
des_eusilc <- convey_prep( des_eusilc )

# coefficients do match
varpoord_gpg_calculation$all_result$value
coef( svygpg( ~ eqincome , des_eusilc , sex = ~ rb090 ) ) * 100

# linearized variables do match
# vardpoor
lin_gpg_varpoord<- varpoord_gpg_calculation$lin_out$lin_gpg
# convey 
lin_gpg_convey <- attr(svygpg( ~ eqincome , des_eusilc, sex = ~ rb090 ),"lin")

# check equality
all.equal(lin_gpg_varpoord,100*lin_gpg_convey[,1] )

# variances do not match exactly
attr( svygpg( ~ eqincome , des_eusilc , sex = ~ rb090 ) , 'var' ) * 10000
varpoord_gpg_calculation$all_result$var

# standard errors do not match exactly
varpoord_gpg_calculation$all_result$se
SE( svygpg( ~ eqincome , des_eusilc , sex = ~ rb090 ) ) * 100
```

The variance estimate is computed by using the approximation defined in \@ref(eq:var), where the linearized variable $z$ is defined by \@ref(eq:lin). The functions `convey::svygpg` and `vardpoor::lingpg` produce the same linearized variable $z$.

However, the measures of uncertainty do not line up, because `library(vardpoor)` defaults to an ultimate cluster method that can be replicated with an alternative setup of the `survey.design` object.

```{r}
# within each strata, sum up the weights
cluster_sums <- aggregate( eusilc$rb050 , list( eusilc$db040 ) , sum )

# name the within-strata sums of weights the `cluster_sum`
names( cluster_sums ) <- c( "db040" , "cluster_sum" )

# merge this column back onto the data.frame
eusilc <- merge( eusilc , cluster_sums )

# construct a survey.design
# with the fpc using the cluster sum
des_eusilc_ultimate_cluster <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc , 
		fpc = ~ cluster_sum 
	)

# again, immediately run the convey_prep function on the `survey.design`
des_eusilc_ultimate_cluster <- convey_prep( des_eusilc_ultimate_cluster )

# matches
attr( svygpg( ~ eqincome , des_eusilc_ultimate_cluster , sex = ~ rb090 ) , 'var' ) * 10000
varpoord_gpg_calculation$all_result$var

# matches
varpoord_gpg_calculation$all_result$se
SE( svygpg( ~ eqincome , des_eusilc_ultimate_cluster , sex = ~ rb090 ) ) * 100
```

For additional usage examples of `svygpg`, type `?convey::svygpg` in the R console.

## Quintile Share Ratio (svyqsr)

Unlike the previous measure, the quintile share ratio is an inequality measure in itself, depending only of the income distribution to evaluate the degree of inequality. By definition, it can be described as the ratio between the income share held by the richest 20% and the poorest 20% of the population. 

In plain terms, it expresses how many times the wealthier part of the population are richer than the poorest part. For instance, a $QSR = 4$ implies that the upper class owns 4 times as much of the total income as the poor.

The quintile share ratio can be modified to a more general function of fractile share ratios. For instance, @cobham2015 presents interesting arguments for using the Palma index, defined as the ratio between the share of the 10% richest over the share held by the poorest 40%.

The details of the linearization of the `QSR` are discussed by @deville1999 and @osier2009.

---

**A replication example**

The R `vardpoor` package [@vardpoor], created by researchers at the Central Statistical Bureau of Latvia, includes a qsr coefficient calculation using the ultimate cluster method.  The example below reproduces those statistics.

Load and prepare the same data set:

```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the vardpoor library
library(vardpoor)

# load the laeken library
library(laeken)

# load the synthetic EU statistics on income & living conditions
data(eusilc)

# make all column names lowercase
names( eusilc ) <- tolower( names( eusilc ) )

# add a column with the row number
dati <- data.table::data.table(IDd = 1 : nrow(eusilc), eusilc)

# calculate the qsr coefficient
# using the R vardpoor library
varpoord_qsr_calculation <-
	varpoord(
	
		# analysis variable
		Y = "eqincome", 
		
		# weights variable
		w_final = "rb050",
		
		# row number variable
		ID_level1 = "IDd",
		
		# row number variable
		ID_level2 = "IDd",
		
		# strata variable
		H = "db040", 
		
		N_h = NULL ,
		
		# clustering variable
		PSU = "rb030", 
		
		# data.table
		dataset = dati, 
		
		# qsr coefficient function
		type = "linqsr",
	  
	  # poverty threshold range
	  order_quant = 50L ,
	  
	  # get linearized variable
	  outp_lin = TRUE
		
	)



# construct a survey.design
# using our recommended setup
des_eusilc <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc
	)

# immediately run the convey_prep function on it
des_eusilc <- convey_prep( des_eusilc )

# coefficients do match
varpoord_qsr_calculation$all_result$value
coef( svyqsr( ~ eqincome , des_eusilc ) )

# linearized variables do match
# vardpoor
lin_qsr_varpoord<- varpoord_qsr_calculation$lin_out$lin_qsr
# convey 
lin_qsr_convey <- attr(svyqsr( ~ eqincome , des_eusilc ),"lin")

# check equality
all.equal(lin_qsr_varpoord, lin_qsr_convey )

# variances do not match exactly
attr( svyqsr( ~ eqincome , des_eusilc ) , 'var' )
varpoord_qsr_calculation$all_result$var

# standard errors do not match exactly
varpoord_qsr_calculation$all_result$se
SE( svyqsr( ~ eqincome , des_eusilc ) )
```

The variance estimate is computed by using the approximation defined in \@ref(eq:var), where the linearized variable $z$ is defined by \@ref(eq:lin). The functions `convey::svygpg` and `vardpoor::lingpg` produce the same linearized variable $z$.

However, the measures of uncertainty do not line up, because `library(vardpoor)` defaults to an ultimate cluster method that can be replicated with an alternative setup of the `survey.design` object.

```{r}
# within each strata, sum up the weights
cluster_sums <- aggregate( eusilc$rb050 , list( eusilc$db040 ) , sum )

# name the within-strata sums of weights the `cluster_sum`
names( cluster_sums ) <- c( "db040" , "cluster_sum" )

# merge this column back onto the data.frame
eusilc <- merge( eusilc , cluster_sums )

# construct a survey.design
# with the fpc using the cluster sum
des_eusilc_ultimate_cluster <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc , 
		fpc = ~ cluster_sum 
	)

# again, immediately run the convey_prep function on the `survey.design`
des_eusilc_ultimate_cluster <- convey_prep( des_eusilc_ultimate_cluster )

# matches
attr( svyqsr( ~ eqincome , des_eusilc_ultimate_cluster ) , 'var' )
varpoord_qsr_calculation$all_result$var

# matches
varpoord_qsr_calculation$all_result$se
SE( svyqsr( ~ eqincome , des_eusilc_ultimate_cluster ) )
```

For additional usage examples of `svyqsr`, type `?convey::svyqsr` in the R console.

## Lorenz Curve (svylorenz)

Though not an inequality measure in itself, the Lorenz curve is a classic instrument of distribution analysis. Basically, it is a function that associates a cumulative share of the population to the share of the total income it owns. In mathematical terms, 

\[
L(p) = \frac{\int_{-\infty}^{Q_p}yf(y)dy}{\int_{-\infty}^{+\infty}yf(y)dy}
\]

where $Q_p$ is the quantile $p$ of the population.

The two extreme distributive cases are 

- Perfect equality:
    - Every individual has the same income;
    - Every share of the population has the same share of the income;
    - Therefore, the reference curve is \[L(p) = p \text{ } \forall p \in [0,1] \text{.}\]
- Perfect inequality:
    - One individual concentrates all of society's income, while the other individuals have zero income;
    - Therefore, the reference curve is 
    
\[
L(p)=
\begin{cases}
0, &\forall p < 1 \\
1, &\text{if } p = 1 \text{.}
\end{cases}
\]
    
In order to evaluate the degree of inequality in a society, the analyst looks at the distance between the real curve and those two reference curves.

The estimator of this function was derived by @kovacevic1997:

\[
L(p) = \frac{ \sum_{i \in S} w_i \cdot y_i \cdot \delta \{ y_i \le \widehat{Q}_p \}}{\widehat{Y}}, \text{ } 0 \le p \le 1.
\]

Yet, this formula is used to calculate specific points of the curve and their respective SEs. The formula to plot an approximation of the continuous empirical curve comes from @lerman1989.

---

**A replication example**

In October 2016, [@jann2016] released a pre-publication working paper to estimate lorenz and concentration curves using stata.  The example below reproduces the statistics presented in his section 4.1.

```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the stata-style webuse library
library(webuse)

# load the NLSW 1988 data
webuse("nlsw88")

# coerce that `tbl_df` to a standard R `data.frame`
nlsw88 <- data.frame( nlsw88 )

# initiate a linearized survey design object
des_nlsw88 <- svydesign( ids = ~1 , data = nlsw88 )

# immediately run the `convey_prep` function on the survey design
des_nlsw88 <- convey_prep(des_nlsw88)

# estimates lorenz curve
result.lin <- svylorenz( ~wage, des_nlsw88, quantiles = seq( 0, 1, .05 ), na.rm = TRUE )


# note: most survey commands in R use Inf degrees of freedom by default
# stata generally uses the degrees of freedom of the survey design.
# therefore, while this extended syntax serves to prove a precise replication of stata
# it is generally not necessary.
section_four_one <-
	data.frame( 
		estimate = coef( result.lin ) , 
		standard_error = SE( result.lin ) , 
		ci_lower_bound = 
		    coef( result.lin ) + 
		    SE( result.lin ) * 
		    qt( 0.025 , degf( subset( des_nlsw88 , !is.na( wage ) ) ) ) ,
		ci_upper_bound = 
		    coef( result.lin ) + 
		    SE( result.lin ) * 
		    qt( 0.975 , degf( subset( des_nlsw88 , !is.na( wage ) ) ) )
	)
	
```

```{r echo=FALSE}
knitr::kable(
  section_four_one ,
  booktabs = TRUE
)
```


For additional usage examples of `svylorenz`, type `?convey::svylorenz` in the R console.


## Gini index (svygini)

The Gini index is an attempt to express the inequality presented in the Lorenz curve as a single number. In essence, it is twice the area between the equality curve and the real Lorenz curve. Put simply:

\[
\begin{aligned}
G &= 2 \bigg( \int_{0}^{1} pdp - \int_{0}^{1} L(p)dp \bigg) \\
\therefore G &= 1 - 2 \int_{0}^{1} L(p)dp
\end{aligned}
\]

where $G=0$ in case of perfect equality and $G = 1$ in the case of perfect inequality.

The estimator proposed by @osier2009 is defined as:

\[
\widehat{G} = \frac{ 2 \sum_{i \in S} w_i r_i y_i - \sum_{i \in S} w_i y_i }{ \hat{Y} }
\]

The linearized formula of $\widehat{G}$ is used to calculate the SE.

---

**A replication example**

The R `vardpoor` package [@vardpoor], created by researchers at the Central Statistical Bureau of Latvia, includes a gini coefficient calculation using the ultimate cluster method.  The example below reproduces those statistics.

Load and prepare the same data set:

```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the vardpoor library
library(vardpoor)

# load the laeken library
library(laeken)

# load the synthetic EU statistics on income & living conditions
data(eusilc)

# make all column names lowercase
names( eusilc ) <- tolower( names( eusilc ) )

# add a column with the row number
dati <- data.table::data.table(IDd = 1 : nrow(eusilc), eusilc)

# calculate the gini coefficient
# using the R vardpoor library
varpoord_gini_calculation <-
	varpoord(
	
		# analysis variable
		Y = "eqincome", 
		
		# weights variable
		w_final = "rb050",
		
		# row number variable
		ID_level1 = "IDd",
		
		# row number variable
		ID_level2 = "IDd",
		
		# strata variable
		H = "db040", 
		
		N_h = NULL ,
		
		# clustering variable
		PSU = "rb030", 
		
		# data.table
		dataset = dati, 
		
		# gini coefficient function
		type = "lingini",
	  
	  # poverty threshold range
	  order_quant = 50L ,
	  
	  # get linearized variable
	  outp_lin = TRUE
		
	)



# construct a survey.design
# using our recommended setup
des_eusilc <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc
	)

# immediately run the convey_prep function on it
des_eusilc <- convey_prep( des_eusilc )

# coefficients do match
varpoord_gini_calculation$all_result$value
coef( svygini( ~ eqincome , des_eusilc ) ) * 100

# linearized variables do match
# varpoord
lin_gini_varpoord<- varpoord_gini_calculation$lin_out$lin_gini
# convey 
lin_gini_convey <- attr(svygini( ~ eqincome , des_eusilc ),"lin")

# check equality
all.equal(lin_gini_varpoord,100*lin_gini_convey )

# variances do not match exactly
attr( svygini( ~ eqincome , des_eusilc ) , 'var' ) * 10000
varpoord_gini_calculation$all_result$var

# standard errors do not match exactly
varpoord_gini_calculation$all_result$se
SE( svygini( ~ eqincome , des_eusilc ) ) * 100
```

The variance estimate is computed by using the approximation defined in \@ref(eq:var), where the linearized variable $z$ is defined by \@ref(eq:lin). The functions `convey::svygini` and `vardpoor::lingini` produce the same linearized variable $z$.

However, the measures of uncertainty do not line up, because `library(vardpoor)` defaults to an ultimate cluster method that can be replicated with an alternative setup of the `survey.design` object.

```{r}
# within each strata, sum up the weights
cluster_sums <- aggregate( eusilc$rb050 , list( eusilc$db040 ) , sum )

# name the within-strata sums of weights the `cluster_sum`
names( cluster_sums ) <- c( "db040" , "cluster_sum" )

# merge this column back onto the data.frame
eusilc <- merge( eusilc , cluster_sums )

# construct a survey.design
# with the fpc using the cluster sum
des_eusilc_ultimate_cluster <- 
	svydesign( 
		ids = ~ rb030 , 
		strata = ~ db040 ,  
		weights = ~ rb050 , 
		data = eusilc , 
		fpc = ~ cluster_sum 
	)

# again, immediately run the convey_prep function on the `survey.design`
des_eusilc_ultimate_cluster <- convey_prep( des_eusilc_ultimate_cluster )

# matches
attr( svygini( ~ eqincome , des_eusilc_ultimate_cluster ) , 'var' ) * 10000
varpoord_gini_calculation$all_result$var

# matches
varpoord_gini_calculation$all_result$se
SE( svygini( ~ eqincome , des_eusilc_ultimate_cluster ) ) * 100
```


## Entropy-based Measures

Entropy is a concept derived from information theory, meaning the expected amount of information given the occurrence of an event. Following [@shannon1948], given an event $y$ with probability density function $f(\cdot)$, the information content given the occurrence of $y$ can be defined as $g(f(y)) \colon= - \log f(y)$. Therefore, the expected information or, put simply, the *entropy* is

\[
H(f) \colon = -E \big[ \log f(y) \big] = - \int_{-\infty}^{\infty} f(y) \log f(y) dy
\]

Assuming a discrete distribution, with $p_k$ as the probability of occurring event $k \in K$, the entropy formula takes the form:

\[
H = - \sum_{k \in K} p_k \log p_k \text{.}
\]

The main idea behind it is that the expected amount of information of an event is inversely proportional to the probability of its occurrence. In other words, the information derived from the observation of a rare event is higher than of the information of more probable events.

Using ideas presented in @cowell2009, substituting the density function by the income share of an individual $s(q) = {F}^{-1}(q) / \int_{0}^{1} F^{-1}(t)dt = y/\mu$, the entropy function becomes the Theil^[Also known as Theil-T index.] inequality index

\[
I_{Theil} = \int_{0}^{\infty} \frac{y}{\mu} \log \bigg( \frac{y}{\mu} \bigg) dF(y) = -H(s)
\]

Therefore, the entropy-based inequality measure increases as a person's income $y$ deviates from the mean $\mu$. This is the basic idea behind entropy-based inequality measures.

## Generalized Entropy and Decomposition (svygei, svygeidec)

Using a generalization of the information function, now defined as $g(f) = \frac{1}{\alpha-1} [ 1 - f^{\alpha - 1} ]$, the $\alpha$-class entropy is 
\[
H_\alpha(f) = \frac{1}{\alpha - 1} \bigg[ 1 - \int_{-\infty}^{\infty} f(y)^{ \alpha - 1} f(y) dy \bigg] \text{.}
\]

This relates to a class of inequality measures, the Generalized entropy indices, defined as:

\[
GE_\alpha = \frac{1}{\alpha^2 - \alpha} \int_{0}^\infty \bigg[ \bigg( \frac{y}{\mu} \bigg)^\alpha - 1 \bigg]dF(x) = - \frac{-H_\alpha(s) }{ \alpha } \text{.}
\]

The parameter $\alpha$ also has an economic interpretation: as $\alpha$ increases, the influence of top incomes upon the index increases. In some cases, this measure takes special forms, such as mean log deviation and the aforementioned Theil index.

In order to estimate it, @biewen2003 proposed the following:

\[
GE_\alpha =
\begin{cases}
( \alpha^2 - \alpha)^{-1} \big[ U_0^{\alpha - 1} U_1^{-\alpha} U_\alpha -1 \big], & \text{if } \alpha \in \mathbb{R} \setminus \{0,1\} \\
- T_0 U_0^{-1} + \log ( U_1 / U_0 ), &\text{if } \alpha \rightarrow 0 \\
T_1 U_1^{-1} - \log ( U_1 / U_0 ), & \text{if } \alpha \rightarrow 1
\end{cases}
\]

where $U_\gamma = \sum_{i \in S} w_i \cdot y_i^\gamma$ and $T_\gamma = \sum_{i \in S} w_i \cdot y_i^\gamma \cdot \log y_i$. Since those are all functions of totals, the linearization of the indices are easily achieved using the theorems described in @deville1999.

This class also has several desirable properties, such as additive decomposition. The additive decomposition allows to compare the effects of inequality within and between population groups on the population inequality. Put simply, an additive decomposable index allows for:

\[
I_{Total} = I_{Between} + I_{Within} \text{.}
\]

---

**A replication example**

In July 2006, @jenkins2006 presented at the North American Stata Users' Group Meetings on the stata Generalized Entropy Index command. The example below reproduces those statistics.

Load and prepare the same data set:
```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the foreign library
library(foreign)

# create a temporary file on the local disk
tf <- tempfile()

# store the location of the presentation file
presentation_zip <- "http://repec.org/nasug2006/nasug2006_jenkins.zip"

# download jenkins' presentation to the temporary file
download.file( presentation_zip , tf , mode = 'wb' )

# unzip the contents of the archive
presentation_files <- unzip( tf , exdir = tempdir() )

# load the institute for fiscal studies' 1981, 1985, and 1991 data.frame objects
x81 <- read.dta( grep( "ifs81" , presentation_files , value = TRUE ) )
x85 <- read.dta( grep( "ifs85" , presentation_files , value = TRUE ) )
x91 <- read.dta( grep( "ifs91" , presentation_files , value = TRUE ) )

# stack each of these three years of data into a single data.frame
x <- rbind( x81 , x85 , x91 )
```

Replicate the author's survey design statement from stata code..
```
. * account for clustering within HHs 
. version 8: svyset [pweight = wgt], psu(hrn)
pweight is wgt
psu is hrn
construct an
```

.. into R code:


```{r}
# initiate a linearized survey design object
y <- svydesign( ~ hrn , data = x , weights = ~ wgt )

# immediately run the `convey_prep` function on the survey design
z <- convey_prep( y )
```

Replicate the author's subset statement and each of his svygei results..
```
. svygei x if year == 1981
 
Warning: x has 20 values = 0. Not used in calculations

Complex survey estimates of Generalized Entropy inequality indices
 
pweight: wgt                                   Number of obs    = 9752
Strata: <one>                                  Number of strata = 1
PSU: hrn                                       Number of PSUs   = 7459
											   Population size  = 54766261
---------------------------------------------------------------------------
Index    |  Estimate   Std. Err.      z      P>|z|     [95% Conf. Interval]
---------+-----------------------------------------------------------------
GE(-1)   |  .1902062   .02474921     7.69    0.000      .1416987   .2387138
MLD      |  .1142851   .00275138    41.54    0.000      .1088925   .1196777
Theil    |  .1116923   .00226489    49.31    0.000      .1072532   .1161314
GE(2)    |   .128793   .00330774    38.94    0.000      .1223099    .135276
GE(3)    |  .1739994   .00662015    26.28    0.000      .1610242   .1869747
---------------------------------------------------------------------------
```

..using R code:

```{r}
z81 <- subset( z , year == 1981 )

svygei( ~ eybhc0 , subset( z81 , eybhc0 > 0 ) , epsilon = -1 )
svygei( ~ eybhc0 , subset( z81 , eybhc0 > 0 ) , epsilon = 0 )
svygei( ~ eybhc0 , subset( z81 , eybhc0 > 0 ) )
svygei( ~ eybhc0 , subset( z81 , eybhc0 > 0 ) , epsilon = 2 )
svygei( ~ eybhc0 , subset( z81 , eybhc0 > 0 ) , epsilon = 3 )
```	

Confirm this replication applies for subsetted objects as well.  Compare stata output..

```
. svygei x if year == 1985 & x >= 1

Complex survey estimates of Generalized Entropy inequality indices
 
pweight: wgt                                   Number of obs    = 8969
Strata: <one>                                  Number of strata = 1
PSU: hrn                                       Number of PSUs   = 6950
											   Population size  = 55042871
---------------------------------------------------------------------------
Index    |  Estimate   Std. Err.      z      P>|z|     [95% Conf. Interval]
---------+-----------------------------------------------------------------
GE(-1)   |  .1602358   .00936931    17.10    0.000      .1418723   .1785993
MLD      |   .127616   .00332187    38.42    0.000      .1211052   .1341267
Theil    |  .1337177   .00406302    32.91    0.000      .1257543    .141681
GE(2)    |  .1676393   .00730057    22.96    0.000      .1533304   .1819481
GE(3)    |  .2609507   .01850689    14.10    0.000      .2246779   .2972235
---------------------------------------------------------------------------
```

..to R code:

```{r}
z85 <- subset( z , year == 1985 )

svygei( ~ eybhc0 , subset( z85 , eybhc0 > 1 ) , epsilon = -1 )
svygei( ~ eybhc0 , subset( z85 , eybhc0 > 1 ) , epsilon = 0 )
svygei( ~ eybhc0 , subset( z85 , eybhc0 > 1 ) )
svygei( ~ eybhc0 , subset( z85 , eybhc0 > 1 ) , epsilon = 2 )
svygei( ~ eybhc0 , subset( z85 , eybhc0 > 1 ) , epsilon = 3 )
```

Replicate the author's decomposition by population subgroup (work status) shown on PDF page 57..
```{r}

# define work status (PDF page 22)
z <- update( z , wkstatus = c( 1 , 1 , 1 , 1 , 2 , 3 , 2 , 2 )[ as.numeric( esbu ) ] )
z <- update( z , factor( wkstatus , labels = c( "1+ ft working" , "no ft working" , "elderly" ) ) )

# subset to 1991 and remove records with zero income
z91 <- subset( z , year == 1991 & eybhc0 > 0 )

# population share
svymean( ~wkstatus, z91 )

# mean
svyby( ~eybhc0, ~wkstatus, z91, svymean )

# subgroup indices: ge_k
svyby( ~ eybhc0 , ~wkstatus , z91 , svygei , epsilon = -1 )
svyby( ~ eybhc0 , ~wkstatus , z91 , svygei , epsilon = 0 )
svyby( ~ eybhc0 , ~wkstatus , z91 , svygei , epsilon = 1 )
svyby( ~ eybhc0 , ~wkstatus , z91 , svygei , epsilon = 2 )

# GE decomposition
svygeidec( ~eybhc0, ~wkstatus, z91, epsilon = -1 )
svygeidec( ~eybhc0, ~wkstatus, z91, epsilon = 0 )
svygeidec( ~eybhc0, ~wkstatus, z91, epsilon = 1 )
svygeidec( ~eybhc0, ~wkstatus, z91, epsilon = 2 )

```

For additional usage examples of `svygei` or `svygeidec`, type `?convey::svygei` or `?convey::svygeidec` in the R console.

## J-Divergence and Decomposition (svyjdiv, svyjdivdec)

The J-divergence measure [@rohde2016] can be seen as the sum of $GE_0$ and $GE_1$, satisfying axioms that, individually, those two indices do not. Using $U_\gamma$ and $T_\gamma$ functions defined in @biewen2003, the estimator can be defined as:

\[
\begin{aligned}
J &= \frac{1}{N} \sum_{i \in S} \bigg( \frac{ y_i - \mu }{ \mu } \bigg) \log \bigg( \frac{y_i}{\mu} \bigg) \\
\therefore \widehat{J} &= \frac{\widehat{T}_1}{\widehat{U}_1} - \frac{ \widehat{T}_0 }{ \widehat{U}_0 }
\end{aligned}
\]

Since it is a sum of two additive decomposable measures, $J$ itself is decomposable.

For additional usage examples of `svyjdiv` or `svyjdivdec`, type `?convey::svyjdiv` or `?convey::svyjdivdec` in the R console.

## Atkinson index (svyatk)

Although the original formula was proposed in @atkinson1970, the estimator used here comes from @biewen2003:

\[
\widehat{A}_\epsilon =
\begin{cases}
 1 - \widehat{U}_0^{ - \epsilon/(1 - \epsilon) } \widehat{U}_1^{ -1 } \widehat{U}_{1 - \epsilon}^{ 1/(1 - \epsilon) } , &\text{if } \epsilon \in \mathbb{R}_+ \setminus\{ 1 \} \\
1 - \widehat{U}_0 \widehat{U}_0^{-1} exp( \widehat{T}_0 \widehat{U}_0^{-1} ), &\text{if } \epsilon \rightarrow1
\end{cases}
\]

The $\epsilon$ is an inequality aversion parameter: as it approaches infinity, more weight is given to incomes in bottom of the distribution.

---

**A replication example**

In July 2006, @jenkins2006 presented at the North American Stata Users' Group Meetings on the stata Atkinson Index command. The example below reproduces those statistics.

Load and prepare the same data set:
```{r}
# load the convey package
library(convey)

# load the survey library
library(survey)

# load the foreign library
library(foreign)

# create a temporary file on the local disk
tf <- tempfile()

# store the location of the presentation file
presentation_zip <- "http://repec.org/nasug2006/nasug2006_jenkins.zip"

# download jenkins' presentation to the temporary file
download.file( presentation_zip , tf , mode = 'wb' )

# unzip the contents of the archive
presentation_files <- unzip( tf , exdir = tempdir() )

# load the institute for fiscal studies' 1981, 1985, and 1991 data.frame objects
x81 <- read.dta( grep( "ifs81" , presentation_files , value = TRUE ) )
x85 <- read.dta( grep( "ifs85" , presentation_files , value = TRUE ) )
x91 <- read.dta( grep( "ifs91" , presentation_files , value = TRUE ) )

# stack each of these three years of data into a single data.frame
x <- rbind( x81 , x85 , x91 )
```

Replicate the author's survey design statement from stata code..
```
. * account for clustering within HHs 
. version 8: svyset [pweight = wgt], psu(hrn)
pweight is wgt
psu is hrn
construct an
```

.. into R code:


```{r}
# initiate a linearized survey design object
y <- svydesign( ~ hrn , data = x , weights = ~ wgt )

# immediately run the `convey_prep` function on the survey design
z <- convey_prep( y )
```

Replicate the author's subset statement and each of his svyatk results with stata..
```
. svyatk x if year == 1981
 
Warning: x has 20 values = 0. Not used in calculations

Complex survey estimates of Atkinson inequality indices
 
pweight: wgt                                   Number of obs    = 9752
Strata: <one>                                  Number of strata = 1
PSU: hrn                                       Number of PSUs   = 7459
                                               Population size  = 54766261
---------------------------------------------------------------------------
Index    |  Estimate   Std. Err.      z      P>|z|     [95% Conf. Interval]
---------+-----------------------------------------------------------------
A(0.5)   |  .0543239   .00107583    50.49    0.000      .0522153   .0564324
A(1)     |  .1079964   .00245424    44.00    0.000      .1031862   .1128066
A(1.5)   |  .1701794   .0066943    25.42    0.000       .1570588      .1833
A(2)     |  .2755788   .02597608    10.61    0.000      .2246666    .326491
A(2.5)   |  .4992701   .06754311     7.39    0.000       .366888   .6316522
---------------------------------------------------------------------------
```

..using R code:

```{r}
z81 <- subset( z , year == 1981 )

svyatk( ~ eybhc0 , subset( z81 , eybhc0 > 0 ) , epsilon = 0.5 )
svyatk( ~ eybhc0 , subset( z81 , eybhc0 > 0 ) )
svyatk( ~ eybhc0 , subset( z81 , eybhc0 > 0 ) , epsilon = 1.5 )
svyatk( ~ eybhc0 , subset( z81 , eybhc0 > 0 ) , epsilon = 2 )
svyatk( ~ eybhc0 , subset( z81 , eybhc0 > 0 ) , epsilon = 2.5 )
```

Confirm this replication applies for subsetted objects as well, comparing stata code..
```
. svyatk x if year == 1981 & x >= 1

Complex survey estimates of Atkinson inequality indices
 
pweight: wgt                                   Number of obs    = 9748
Strata: <one>                                  Number of strata = 1
PSU: hrn                                       Number of PSUs   = 7457
                                               Population size  = 54744234
---------------------------------------------------------------------------
Index    |  Estimate   Std. Err.      z      P>|z|     [95% Conf. Interval]
---------+-----------------------------------------------------------------
A(0.5)   |  .0540059   .00105011    51.43    0.000      .0519477   .0560641
A(1)     |  .1066082   .00223318    47.74    0.000      .1022313   .1109852
A(1.5)   |  .1638299   .00483069    33.91    0.000       .154362   .1732979
A(2)     |  .2443206   .01425258    17.14    0.000      .2163861   .2722552
A(2.5)   |   .394787   .04155221     9.50    0.000      .3133461   .4762278
---------------------------------------------------------------------------
```

..to R code:

```{r}
z81_two <- subset( z , year == 1981 & eybhc0 > 1 )

svyatk( ~ eybhc0 , z81_two , epsilon = 0.5 )
svyatk( ~ eybhc0 , z81_two )
svyatk( ~ eybhc0 , z81_two , epsilon = 1.5 )
svyatk( ~ eybhc0 , z81_two , epsilon = 2 )
svyatk( ~ eybhc0 , z81_two , epsilon = 2.5 )
```

For additional usage examples of `svyatk`, type `?convey::svyatk` in the R console.

## Which inequality measure should be used?

The variety of inequality measures begs a question: which inequality measure shuold be used? In fact, this is a very important question. However, the nature of it is not statistical or mathematical, but ethical. This section aims to clarify and, while not proposing a "perfect measure", to provide the reader with an initial guidance about which measure to use.

The most general way to analyze if one distribution is more equally distributed than another is by the Lorenz curve. When $L_A(p) \geqslant L_B(p), \forall p \in [0,1]$, it is said that $A$ is more equally distributed than $B$. Technically, we say that $A$ *(Lorenz )dominates* $B$^[@kramer1998 and @mosler1994 provide helpful insights to how majorization, Lorenz dominance, and inequality measurement are connected. On the topic of majorization, @hardy1934 is still the main reference, while @olkin2011 provide a more modern approach.]. In this case, all inequality measures that satisfy basic properties^[Namely, Schur-convexity, population invariance, and scale invariance.] will agree that $A$ is more equally distributed than $B$. 

When this dominance fails, i.e., when Lorenz curves do cross, Lorenz ordering is impossible. Then, under such circumstances, the choice of which inequality measure to use becomes relevant.

Each inequality measure is a result of a subjective understanding of what is a fair distribution. As @dalton1920 [p.348] puts it, "[...] the economist is primarily interested, not in the distribution of income as such, but in the effects of the distribution of income upon the distribution and total amount of economic welfare, which may be derived from income." The importance of how economic welfare is defined is once again expressed by @atkinson1970, where an inequality measure is direclty derived from a class of welfare functions. Even when a welfare function is not explicit, such as in the Gini index, we must agree that an implicit, subjective judgement of the impact of inequality on social welfare is assumed.

The idea of what is a fair distribution is a matter of Ethics, a discipline within the realm of Philosophy. Yet, as @fleur1996 [Ch.1] proposes, the analyst should match socially supported moral values and theories of justice to the set of technical tools for policy evaluation. 

Although this can be a useful principle, a more objective answer is needed. By knowing the nature and properties of inequality measures, the analyst can further reduce the set of applicable inequality measures. For instance, choosing from the properties listed in @cowell2011 [p.74], if we require group-decomposability, scale invariance, population invariance, and that the estimate in $[0,1]$, we must resort to the Atkinson index.

Even though the discussion can go deep in technical and philosophical aspects, this choice also depends on the public. For example, it would not be surprising if a public official doesn't know the Atkinson index; however, he might know the Gini index. The same goes for publications: journalists have been introduced to the Gini index and can find it easier to compare and, therefore, write about it. Also, we must admit that the Gini index is much more straightforward than any other measure. 

In the end, the choice is mostly subjective and there is no consensus of which is the "greatest inequality measure". We must remember that this choice is only problematic if Lorenz curves cross and, in that case, it is not difficult to justify the use of this or that inequality measure.

<!--chapter:end:02-inequality.Rmd-->

